{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "from numpy import *\n",
    "\n",
    "import os\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage import data, io, filters\n",
    "\n",
    "from matplotlib.path import Path\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import pandas as pd\n",
    "import helpers as helpers\n",
    "\n",
    "\n",
    "class SketchDataset():\n",
    "    \"\"\"dataset of photos and sketches for pix2svg.\"\"\"\n",
    "\n",
    "    def __init__(self, npy_file, photo_dir, class_name, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            npy_file (string): Path to the numpy file with stroke-5 representation and corresponding photos.\n",
    "                    # to get stroke-5 representation of svg\n",
    "                    x['airplane'][0][5]\n",
    "                    # to get corresponding sketch path\n",
    "                    x['airplane'][1][5]\n",
    "            photo_dir (string): Directory with all the photos.\n",
    "            class_name: name of category (e.g., airplane)\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.stroke_dir = npy_file\n",
    "        self.photo_dir = photo_dir\n",
    "        self.class_name = class_name\n",
    "        self.strokes = np.load(npy_file)[()]\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.strokes[self.class_name][0])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = self.strokes\n",
    "        filelist = X[self.class_name][1]\n",
    "        photo_filename = filelist[idx].split('/')[-1].split('.')[0].split('-')[0] + '.jpg'\n",
    "        if self.class_name=='car_(sedan)':\n",
    "            _cname = 'car'\n",
    "        else:\n",
    "            _cname = self.class_name\n",
    "        photo_path = os.path.join(self.photo_dir,_cname,photo_filename)                               \n",
    "        photo = io.imread(photo_path)\n",
    "        photo = photo.astype(float)\n",
    "        strokes = self.strokes[self.class_name][0][idx]\n",
    "        sketch_filename = filelist[idx].split('/')[-1].split('.')[0] + '.png'\n",
    "        sample = {'photo': photo, 'strokes': strokes,'name': photo_filename, 'sketch_filename': sketch_filename}        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample    \n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, strokes, name = sample['photo'], sample['strokes'], sample['name']\n",
    "\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        image = image.transpose((2, 0, 1))        \n",
    "        return {'tensor': tf.divide(tf.stack(sample['photo']),255),\n",
    "                'strokes': strokes,\n",
    "                'name': name,\n",
    "                'photo': image}    \n",
    "\n",
    "def to_normal_strokes(big_stroke):\n",
    "    \"\"\"Convert from stroke-5 format (from sketch-rnn paper) back to stroke-3.\"\"\"\n",
    "    l = 0\n",
    "    for i in range(len(big_stroke)):\n",
    "        if big_stroke[i, 4] > 0:\n",
    "            l = i\n",
    "            break\n",
    "    if l == 0:\n",
    "        l = len(big_stroke)\n",
    "    result = np.zeros((l, 3))\n",
    "    result[:, 0:2] = big_stroke[0:l, 0:2]\n",
    "    result[:, 2] = big_stroke[0:l, 3]\n",
    "    return result    \n",
    "    \n",
    "def strokes_to_lines(strokes):\n",
    "    \"\"\"\n",
    "    Convert stroke-3 format to polyline format.\n",
    "    List contains sublist of continuous line segments (strokes).    \n",
    "    \"\"\"\n",
    "    x = 0\n",
    "    y = 0\n",
    "    lines = []\n",
    "    line = []\n",
    "    for i in range(len(strokes)):\n",
    "        if strokes[i, 2] == 1:\n",
    "            x += float(strokes[i, 0])\n",
    "            y += float(strokes[i, 1])\n",
    "            line.append([x, y])\n",
    "            lines.append(line)\n",
    "            line = []\n",
    "        else:\n",
    "            x += float(strokes[i, 0])\n",
    "            y += float(strokes[i, 1])\n",
    "            line.append([x, y])\n",
    "    return lines\n",
    "\n",
    "def polyline_pathmaker(lines):\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    codes = [Path.MOVETO] # start with moveto command always\n",
    "    for i,l in enumerate(lines):\n",
    "        for _i,_l in enumerate(l):\n",
    "            x.append(_l[0])\n",
    "            y.append(_l[1])\n",
    "            if _i<len(l)-1:\n",
    "                codes.append(Path.LINETO) # keep pen on page\n",
    "            else:\n",
    "                if i != len(lines)-1: # final vertex\n",
    "                    codes.append(Path.MOVETO)\n",
    "    verts = zip(x,y)            \n",
    "    return verts, codes\n",
    "\n",
    "def path_renderer(verts, codes):\n",
    "    if len(verts)>0:\n",
    "        path = Path(verts, codes)\n",
    "        patch = patches.PathPatch(path, facecolor='none', lw=2)\n",
    "        ax.add_patch(patch)\n",
    "        ax.set_xlim(0,640)\n",
    "        ax.set_ylim(0,640) \n",
    "        ax.axis('off')\n",
    "        plt.gca().invert_yaxis() # y values increase as you go down in image\n",
    "        plt.show()\n",
    "    else:\n",
    "        ax.set_xlim(0,640)\n",
    "        ax.set_ylim(0,640)        \n",
    "        ax.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "def flatten(x):\n",
    "    return [item for sublist in x for item in sublist]        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = './sketch_coords'\n",
    "save_dir = './stroke_dataframes_hierarchical'\n",
    "photo_dir = '/home/jefan/full_sketchy_dataset/photos'\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "all_classes = os.listdir(root_dir)\n",
    "\n",
    "# all_classes = ['coords_car_(sedan).npy']\n",
    "\n",
    "for c in all_classes:\n",
    "    cname = c.split('.')[0][7:]\n",
    "    \n",
    "#     # catch car exception\n",
    "#     if cname=='car_(sedan)':\n",
    "#         cname = 'car'\n",
    "   \n",
    "    ## load in each dataset\n",
    "    Class = SketchDataset(npy_file=os.path.join(root_dir,c), \\\n",
    "                            photo_dir=photo_dir, class_name=cname, transform=None)    \n",
    "\n",
    "    ## loop through Class and save photos and sketchID's indexed in same way as full_sketchy_dataset is organized\n",
    "    photos = []\n",
    "    sketchID = []\n",
    "    sketchFN = []\n",
    "    counter = 1\n",
    "    for i in range(len(Class)):\n",
    "        photos.append(Class[i]['name'].split('.')[0])\n",
    "        sketchFN.append(Class[i]['sketch_filename'])\n",
    "        if i==0:\n",
    "            sketchID.append(1)\n",
    "        elif Class[i]['name'].split('.')[0] == Class[i-1]['name'].split('.')[0]: # current matches previous\n",
    "            counter = counter + 1\n",
    "            sketchID.append(counter)\n",
    "        elif Class[i]['name'].split('.')[0] != Class[i-1]['name'].split('.')[0]: # new photo dir\n",
    "            counter = 1\n",
    "            sketchID.append(counter)\n",
    "\n",
    "    unique_photos = np.unique(photos)\n",
    "    zipped = zip(photos,sketchID,sketchFN)    \n",
    "\n",
    "    ##### save out full stroke matrix (55855,5): columns are: [x,y,pen_state,sketch_id,photo_id]\n",
    "    ##### save out individual csv for each image\n",
    "    \n",
    "    for idx in range(len(Class)):\n",
    "        S = [] # initialize stroke dataframe\n",
    "        Verts = []\n",
    "        Codes = []\n",
    "        PhotoID = [] # object-level\n",
    "        SketchID = [] # sketch-level\n",
    "        StrokeID = [] # stroke-level\n",
    "        SketchFN = [] # sketch png filename        \n",
    "        \n",
    "        \n",
    "        sample = Class[idx]\n",
    "        this_sketchFN = zipped[idx][2]\n",
    "        this_sketchID = zipped[idx][1]\n",
    "        this_photoID = zipped[idx][0]\n",
    "        lines = strokes_to_lines(to_normal_strokes(sample['strokes']))\n",
    "        verts,codes = polyline_pathmaker(lines)\n",
    "        Verts.append(verts)\n",
    "        Codes.append(codes)\n",
    "        SketchID.append([this_sketchID]*len(verts))\n",
    "        PhotoID.append([this_photoID]*len(verts))\n",
    "        SketchFN.append([this_sketchFN]*len(verts))\n",
    "        strokeID = []\n",
    "        for i,l in enumerate(lines):\n",
    "            strokeID.append([i]*len(l))\n",
    "        StrokeID.append(flatten(strokeID))\n",
    "\n",
    "\n",
    "        Verts,Codes,SketchID,PhotoID,StrokeID,SketchFN = map(flatten,[Verts,Codes,SketchID,PhotoID,StrokeID,SketchFN]) \n",
    "        x,y = zip(*Verts) # unzip x,y segments \n",
    "        print str(len(Verts)) + ' vertices to predict.'\n",
    "\n",
    "        data = np.array([x,y,Codes,StrokeID,SketchID,PhotoID, SketchFN]).T\n",
    "        S = pd.DataFrame(data,columns=['x','y','pen','strokeID','sketchID','photoID','sketchFN'])\n",
    "        print 'Saving out stroke_dataframe for {} {}'.format(this_sketchFN.split('.')[0],cname)\n",
    "        if not os.path.exists(os.path.join(save_dir,cname)):\n",
    "            os.makedirs(os.path.join(save_dir,cname))\n",
    "        save_path = os.path.join(save_dir,cname, '{}.csv'.format(this_sketchFN.split('.')[0]))\n",
    "        S.to_csv(save_path)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
